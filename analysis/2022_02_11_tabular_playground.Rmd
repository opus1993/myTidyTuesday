---
title: "Identify Bacteria in Kaggle Tabular Playground"
author: "Jim Gruman"
date: "February 11, 2022"
output:
  workflowr::wflow_html:
    toc: no
    code_folding: hide
    code_download: true
    df_print: paged
editor_options:
  chunk_output_type: console
---

For the February 2022 Tabular Playground Series competition, our task is to classify 10 different bacteria species using data from a genomic analysis technique that has some data compression and loss. In this technique, 10-mer snippets of DNA are sampled and analyzed to give histograms of base count. The question: Can we use this information to accurately predict the classification of ten bacteria species?

The idea for this competition came from the following [paper](https://www.frontiersin.org/articles/10.3389/fmicb.2020.00257/full):

> @ARTICLE{10.3389/fmicb.2020.00257,
AUTHOR={Wood, Ryan L. and Jensen, Tanner and Wadsworth, Cindi and Clement, Mark and Nagpal, Prashant and Pitt, William G.},   
TITLE={Analysis of Identification Method for Bacterial Species and Antibiotic Resistance Genes Using Optical Data From DNA Oligomers},      
JOURNAL={Frontiers in Microbiology},      
VOLUME={11},      
YEAR={2020},      
URL={https://www.frontiersin.org/article/10.3389/fmicb.2020.00257},       
DOI={10.3389/fmicb.2020.00257},      
ISSN={1664-302X}}

Let's load up packages:

```{r setup}

suppressPackageStartupMessages({
library(tidyverse) # clean and transform rectangular data
library(collapse) # dplyr accelerators
library(tidymodels) # machine learning tools
library(bestNormalize) # Performs a suite of normalizing transformations, and selects the best one on the basis of the Pearson P test statistic for normality.
  
library(ggforce) # ggplot extensions
library(workflowsets)
library(stacks)
})

source(here::here("code","_common.R"),
       verbose = FALSE,
       local = knitr::knit_global())

ggplot2::theme_set(theme_jim(base_size = 12))

#create a data directory
data_dir <- here::here("data",Sys.Date())
if (!file.exists(data_dir)) dir.create(data_dir)

# set a competition metric
mset <- metric_set(mn_log_loss, accuracy, roc_auc)

# set the competition name from the web address
competition_name <- "tabular-playground-series-feb-2022"

zipfile <- paste0(data_dir,"/", competition_name, ".zip")

path_export <- here::here("data",Sys.Date(),paste0(competition_name,".csv"))
```

## Get the Data

A quick reminder before downloading the dataset:  Go to the web site and accept the competition terms!!!

We have basic shell commands available to interact with Kaggle here:

```{r kaggle competitions terminal commands, eval=FALSE}
# from the Kaggle api https://github.com/Kaggle/kaggle-api

# the leaderboard
shell(glue::glue('kaggle competitions leaderboard { competition_name } -s'))

# the files to download
shell(glue::glue('kaggle competitions files -c { competition_name }'))

# the command to download files
shell(glue::glue('kaggle competitions download -c { competition_name } -p { data_dir }'))

# unzip the files received
shell(glue::glue('unzip { zipfile } -d { data_dir }'))

```

```{r kaggle competitions commands using reticulate, eval=FALSE}

# library(reticulate)
# 
# kaggle <- import("kaggle")
# 
# kaggle$api$competition_download_leaderboard(competition_name)
# 
# kaggle$api$competition_list_files(competition = competition_name)
# 
# kaggle$api$competition_download_files(competition = competition_name,
#                                       path = here::here("data"))
# 
# # unzip the files received
# system2(glue::glue('unzip { zipfile } -d { data_dir }'))

```

We are reading in the contents of the datafiles here.

```{r read kaggle files}

train_df <- arrow::read_csv_arrow(file = glue::glue({ data_dir }, "/train.csv")) %>% 
  mutate(target = factor(target)) %>% 
  distinct(across(contains("A")), .keep_all = TRUE) 

holdout_df <- arrow::read_csv_arrow(file = glue::glue({ data_dir }, "/test.csv")) 

```

Some questions to answer here:
What features have missing data, and imputations may be required?
What does the outcome variable look like, in terms of imbalance?

```{r skim, eval=FALSE}
skimr::skim(train_df)
```

For this challenge, we will be predicting bacteria species based on repeated lossy measurements of DNA snippets. Snippets of length 10 are analyzed using Raman spectroscopy that calculates the histogram of bases in the snippet. In other words, the DNA segment $ATATGGCCTT$ becomes $A_2T_4G_2C_2$ .

Each row of data contains a spectrum of histograms generated by repeated measurements of a sample, each row containing the output of all 286 histogram possibilities (e.g., $A_0T_0G_0C_{10}$ to $A_{10}T_0G_0C_0$ ), which then has a bias spectrum (of totally random ATGC) subtracted from the results.

The data (both train and test) also contains simulated measurement errors (of varying rates) for many of the samples, which makes the problem more challenging.

The target variable appears to be more or less balanced across the classes. I am choosing to remove the duplicate observations before modeling. 

Many features ordered adjacent to one another alphabetically appear to have strong pairwise correlations. Spending some time on feature engineering and dimensionality reduction will likely be our best bet before diving into training a machine learning algorithm.

## Preprocessing

There are too many predictors in the dataset. We will have to perform a preprocessing algorithm to reduce dimensionality. I will try with:

- PCA
- SVD
- UMAP

Let's set up a starter recipe to build from.

```{r}
bacteria_rec <- recipe(target ~ ., data = train_df) %>% 
  update_role(row_id, new_role = "ID") %>% 
  bestNormalize::step_orderNorm(all_numeric_predictors()) %>% 
  step_normalize(all_numeric_predictors())

```

Since recipes are the primary option in tidymodels for dimensionality reduction, letâ€™s write a function that will estimate the transformation and plot the resulting data in a scatter plot matrix via the `ggforce` package:

```{r}
plot_results <- function(recipe, dat = train_df) {
  recipe %>%
    # Estimate any additional steps
    prep() %>%
    # Process the data (the validation set by default)
    bake(new_data = select(dat, -row_id)) %>%
    # Create the scatterplot matrix
    ggplot(aes(x = .panel_x, y = .panel_y, color = target, fill = target)) +
    geom_point(alpha = 0.4, size = 0.5) +
    geom_autodensity(alpha = .3) +
    facet_matrix(vars(-target), layer.diag = 2)  +
    labs(fill = NULL, color = NULL)
}
```

### Principal Components Analysis

```{r pca, fig.asp=1}

prep(bacteria_rec) %>% 
  step_pca(all_numeric_predictors(), num_comp = 3) %>%
  plot_results() + 
  ggtitle("Principal Component Analysis")

```

There are clearly several non-linear groupings in the training data. I am guessing that that the clear groupings are the actual data, and that the overlapping portion is the noise that was added. 

### Sparse Regularized Low-rank Matrix approximation

```{r svd, fig.asp=1}

prep(bacteria_rec) %>%
  embed::step_pca_sparse(
    all_numeric_predictors(),
    num_comp = 3,
    predictor_prop = 0.99,
    options = list(
      maxit = 500,
      tol = 0.001,
      center = FALSE,
      scale. = FALSE,
      alpha = 0,
      tsvd = NULL
    ),
    res = NULL,
    prefix = "PC",
    keep_original_cols = FALSE,
    skip = FALSE,
    id = rand_id("pca_sparse")
  ) %>% 
  plot_results() + 
  ggtitle("Singular Value Decomposition")

```

### Uniform Manifold Approximation and Projection

UMAP is a nonlinear dimension reduction technique that finds local, low-dimensional representations of the data similar to the popular t-SNE method. In the original high-dimensional space, UMAP uses a distance-based nearest neighbor method to find local areas of the data where the data points are more likely to be related. The relationship between data points is saved as a directed graph model where most points are not connected.

From there, UMAP translates points in the graph to the reduced dimensional space. To do this, the algorithm has an optimization process that uses cross-entropy to map data points to the smaller set of features so that the graph is well approximated.

```{r umap, fig.asp=1}
prep(bacteria_rec) %>%
    embed::step_umap(all_numeric_predictors(), 
                   num_comp = 3,
                   neighbors = 70,
                   min_dist = 0.01,  # default is 0.01
                   learn_rate = 10^(-6),  # default is 1
                   epochs = 200, # default is 200
                   options = list(verbose = FALSE, 
                                  n_threads = 1),
                   seed = sample(10^5, 2),
                   prefix = "UMAP",
                   keep_original_cols = FALSE,
                   object = NULL,
                   skip = FALSE,
                   id = rand_id("umap")) %>%
  plot_results() + 
  ggtitle("UMAP")
```

While the between-cluster space is pronounced, several clusters still contain a heterogeneous mixture of classes.

----

# Machine Learning {.tabset}

## Cross Validation

We will use 5-fold cross validation and stratify on the outcome to build models that are less likely to over-fit the training data.  As a sound modeling practice, I am going to hold 3% of the training data out to assess the model performance prior to submission.

```{r cross validation}
set.seed(2021)

split <- initial_split(train_df, prop = 0.97)

training <- training(split)
testing <- testing(split)

(folds <- vfold_cv(training, v = 5, strata = target))

```

## The recipes

To move quickly let's start with this basic recipe with an arbitrary number of UMAP components, and a comparable Singular Value Decomposition.

```{r basic recipe}
umap_rec <- bacteria_rec   %>%
    embed::step_umap(all_numeric_predictors(), 
                   num_comp = 6,
                   neighbors = 70,
                   min_dist = 0.01,  # default is 0.01
                   learn_rate = 10^(-6),  # default is 1
                   epochs = 200, # default is 200
                   options = list(verbose = FALSE, 
                                  n_threads = 1),
                   seed = sample(10^5, 2),
                   prefix = "UMAP",
                   keep_original_cols = FALSE,
                   object = NULL,
                   skip = FALSE,
                   id = rand_id("umap"))

svd_rec <- bacteria_rec %>% 
  embed::step_pca_sparse(
    all_numeric_predictors(),
    num_comp = 8,
    predictor_prop = 0.99,
    options = list(
      maxit = 500,
      tol = 0.001,
      center = FALSE,
      scale. = FALSE,
      alpha = 0,
      tsvd = NULL
    ),
    res = NULL,
    prefix = "PC",
    keep_original_cols = FALSE,
    skip = FALSE,
    id = rand_id("pca_sparse")
  )

```

## Model Specifications

This first model is a bagged tree, where the number of predictors to consider for each split of a tree (i.e., mtry) equals the number of all available predictors. The `min_n` of 19 means that each tree branch of the 50 decision trees built have at least 19 observations. As a result, the decision trees in the ensemble all are relatively shallow.

```{r random forest spec}

bag_spec <-
  baguette::bag_tree(min_n = 19,
                     tree_depth = 14,
                     cost_complexity = 0.0000559) %>%
  set_engine("rpart", times = 50) %>%
  set_mode("classification")

mlp_nnet_spec <-
  mlp(hidden_units = 8, 
      penalty = 0.000005, 
      epochs = 600) %>%
  set_engine('nnet') %>%
  set_mode('classification')

```

## Parallel backend

To speed up computation we will use a parallel backend.

```{r parallel backend}
all_cores <- parallelly::availableCores(omit = 1)
all_cores

future::plan("multisession", workers = all_cores) # on Windows

```

## Build the workflowsets of models to stack

```{r workflowsets}

all_workflows <- 
   workflow_set(
      preproc = list(umap = umap_rec,
                     svd = svd_rec), 
      models = list(random_forest = bag_spec, 
                    neural_network = mlp_nnet_spec)
   )

grid_ctrl <-
   control_stack_resamples()

system.time(xfun::cache_rds(
  expr = {
  grid_results <-
    all_workflows %>%
    workflow_map(seed = 2022,
                 resamples = folds,
                 verbose = TRUE,
                 control = grid_ctrl)
  }, 
  dir = "data/",
  file = "cache.rds"))

```

How did these results turn out? The metrics and confusion matrix are across the cross validation holdouts.

```{r}
grid_results %>% 
   rank_results() %>% 
   filter(.metric == "accuracy") %>% 
   dplyr::select(model, wflow_id, accuracy = mean, rank)
```

We're going to go straight into an ensemble.

```{r}
xfun::cache_rds(
  expr = {

fitted_members <- 
  stacks() %>% 
  add_candidates(grid_results) %>% 
  blend_predictions() %>% 
  fit_members()

}, dir = "data/",
   file = "cache2.rds")

```

Let's have a look at how the ensemble puts the underlying models together. 

```{r, fig.asp =1}
autoplot(fitted_members)

autoplot(fitted_members, "weights") +
  geom_text(aes(x = weight + 0.01, label = model), hjust = 0) + 
  theme(legend.position = "none") +
  lims(x = c(-0.01, 0.75))
```

### Test set results

```{r}
predict(fitted_members, testing) %>% 
  bind_cols(testing) %>% 
  conf_mat(target, .pred_class) %>% 
  autoplot(type = "heatmap")

```

As with the published academic paper, there are a couple of classes of bacteria that resemble one another and are more difficult to discern.

```{r, fig.asp=1}
predict(fitted_members, training, type = "prob") %>%
  bind_cols(dplyr::select(training, target)) %>% 
  roc_curve(truth = target, starts_with(".pred")) %>%
  ggplot(aes(1 - specificity, sensitivity, color = .level)) +
  geom_abline(lty = 2, color = "gray80", size = 1.5) +
  geom_path(alpha = 0.8, size = 1) +
  coord_equal() +
  labs(color = NULL,
       title = "AUC and Classification performance power across cutoff values")
```

```{r, eval=FALSE}
predict(fitted_members, holdout_df) %>% 
  bind_cols(dplyr::select(holdout_df, rowid)) %>% 
  write_csv(file = here::here("data","ensemble_submission.csv"))
```

We're out of time. This will be as good as it gets, and our final submission.

```{r post csv xgboost2, eval = FALSE}
shell(glue::glue('kaggle competitions submit -c { competition_name } -f { path_export } -m "my model"'))
```


